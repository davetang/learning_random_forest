---
title: "Running Random Forests in parallel"
output:
   md_document:
      variant: markdown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(fig.path = "img/")
```

## Introduction

There is a `combine` function in the `randomForest` package that combines two or more ensembles of trees into one. Therefore, we can train ensembles in parallel and combine them! This is useful for large datasets or for testing different parameters.

Install the required packages if missing and then load them.

```{r load_package, message=FALSE, warning=FALSE}
.libPaths('/packages')
my_packages <- c('randomForest', 'foreach', 'doParallel', 'parallel', 'doRNG')

for (my_package in my_packages){
   if(!require(my_package, character.only = TRUE)){
      install.packages(my_package, '/packages')
      library(my_package, character.only = TRUE)
   }
}
```

## Load data

We will use the [Letter Recognition Data Set](https://archive.ics.uci.edu/ml/datasets/Letter+Recognition) which has 20,000 cases, 16 features, and 26 labels.

```{r load_data}
my_url <- 'https://archive.ics.uci.edu/ml/machine-learning-databases/letter-recognition/letter-recognition.data'
my_df <- read.table(file=url(my_url), header=FALSE, sep=',')
colnames(my_df) <- c('class', 'xbox', 'ybox', 'width', 'high', 'onpix', 'xbar', 'ybar', 'x2bar', 'y2bar', 'xybar', 'x2ybr', 'xy2br', 'xege', 'xegvy', 'yege', 'yegvx')
my_df$class <- factor(my_df$class, levels = LETTERS)

dim(my_df)
table(my_df$class)
```

## Metrics

Write a function to calculate metrics.

```{r metric}
metric <- function(rf, type = "accuracy"){
   # not used for now
   # tab <- table(rf$y, rf$predicted)
   # accuracy <- (TP + TN) / (TP + FN + FP + TN)
   # precision <- TP / (TP + FP)
   # recall <- TP / (TP + FN)
   # specificity <- TN / (TN + FP)
   if(type == "accuracy"){
      return(sum(rf$predicted == rf$y) / length(rf$y))
   } else {
      return(NULL)
   }
}
```

## Training

Train random forests model with 2,000 trees without parallelisation.

```{r my_rf}
set.seed(1984)
my_time <- system.time(
   my_rf <- randomForest(
      class ~ .,
      data = my_df,
      ntree = 2000
   )
)

my_time

metric(my_rf)
```

Train random forests with 2,000 trees in parallel. Note the line of code `registerDoRNG(seed = 1984)`: this is to ensure that we train the same model even with parallelisation.

```{r my_rf_par}
cl <- makeCluster(10)
registerDoParallel(cl)
registerDoRNG(seed = 1984)

my_time_par <- system.time(
   my_rf_par <- foreach(
      ntree = rep(200, 10),
      .combine = combine,
      .packages = 'randomForest'
   ) %dopar% {
      randomForest(class ~ ., data = my_df, ntree=ntree)
   }
)
stopCluster(cl)

my_time_par

metric(my_rf_par)
```

[Set `.multicombine = TRUE`](https://stackoverflow.com/questions/14106010/parallel-execution-of-random-forest-in-r) to further increase the speed up. As per the [documentation](https://cran.r-project.org/web/packages/foreach/foreach.pdf), the `.multicombine` argument is a:

>logical flag indicating whether the .combine function can accept more than two arguments. If an arbitrary .combine function is specified, by default, that function will always be called with two arguments. If it can take more than two arguments, then setting .multicombine to TRUE could improve the performance. The default value is FALSE unless the .combine function is cbind, rbind, or c, which are known to take more than two arguments.

```{r my_rf_par_mc}
cl <- makeCluster(10)
registerDoParallel(cl)
registerDoRNG(seed = 1984)

my_time_par_mc <- system.time(
   my_rf_par_mc <- foreach(
      ntree = rep(200, 10),
      .combine = combine,
      .multicombine = TRUE,
      .packages = 'randomForest'
   ) %dopar% {
      randomForest(class ~ ., data = my_df, ntree=ntree)
   }
)
stopCluster(cl)

my_time_par_mc

metric(my_rf_par_mc)
```

As noted in the [documentation](https://cran.r-project.org/web/packages/randomForest/randomForest.pdf) in the `combine` section:

>The confusion, err.rate, mse and rsq components (as well as the corresponding components in the test compnent, if exist) of the combined object will be NULL.

But we can calculate those ourselves, if we want.

```{r setdiff}
# confusion matrix, not run
# table(my_df$class, my_rf_par_mc$predicted)

setdiff(names(my_rf), names(my_rf_par_mc))
```

Most predictions are the same between the model trained without and with parallelisation.

```{r compare_rf}
table(my_rf$predicted == my_rf_par_mc$predicted)
```

## Tuning

Check accuracy as a function of the number of trees.

```{r test_ntree}
my_models <- list()
my_time_ntree <- system.time(
   for(n in seq(from = 500, to = 2000, by = 500)){
      set.seed(1984)
      my_rf <- randomForest(
         class ~ .,
         data = my_df,
         ntree = n
      )
      my_models[[paste0("ntree_", n)]] <- my_rf
   }
)

my_time_ntree
sort(sapply(my_models, metric))
```

Check accuracy as a function of the number of trees in parallel.

```{r test_ntree_foreach}
cl <- makeCluster(4)
registerDoParallel(cl)
registerDoRNG(seed = 1984)

my_time_ntree_par <- system.time(
   my_models_par <- foreach(
      ntree = seq(from = 500, to = 2000, by = 500),
      .packages = 'randomForest'
   ) %dopar% {
      randomForest(class ~ ., data = my_df, ntree = ntree)
   }
)
stopCluster(cl)

my_time_ntree_par
sapply(my_models_par, metric)
```

Check accuracy as a function of the number of trees and features in parallel.

```{r test_ntree_mtry_foreach}
cl <- makeCluster(32)
registerDoParallel(cl)
registerDoRNG(seed = 1984)

ntrees <- seq(from = 500, to = 2000, by = 500)
mtrys <- 1:ncol(my_df)
my_grid <- expand.grid(ntrees, mtrys)

my_time_ntree_mtry_par <- system.time(
   my_models_mtry_par <- foreach(ntree = my_grid$Var1, mtry = my_grid$Var2, .packages = 'randomForest') %dopar% {
      randomForest(class ~ ., data = my_df, ntree = ntree, mtry = mtry)
   }
)

stopCluster(cl)
my_time_ntree_mtry_par

my_grid$accuracy <- sapply(my_models_mtry_par, metric)

head(my_grid[order(my_grid$accuracy, decreasing = TRUE), ])
```

## Session info

Time built.

```{r time, echo=FALSE}
Sys.time()
```

Session info.

```{r session_info, echo=FALSE}
sessionInfo()
```
